{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "mnistDigitClassifier.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HDWilliams/mnistDigitClassifier/blob/master/mnistDigitClassifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rwX6iv81WtYp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#import necessary libraries\n",
        "import torch\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision import transforms, datasets\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0EMiafPAXAmG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#set up data transforms and import data\n",
        "transform = transforms.Compose([transforms.ToTensor()])\n",
        "\n",
        "#set up train and test dataloaders\n",
        "trainset = datasets.MNIST('../mnist_data', download=True, train=True, transform=transform)\n",
        "train_dataloader = torch.utils.data.DataLoader(trainset, batch_size=16, shuffle=True)\n",
        "\n",
        "testset = datasets.MNIST('../mnist_data', download=True, train=False, transform=transform)\n",
        "test_dataloader = torch.utils.data.DataLoader(testset, batch_size=16, shuffle = True)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ENfDFcE-XWAU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "outputId": "e68197bc-b7de-4967-ef33-5e78582ad77d"
      },
      "source": [
        "#visualize the images\n",
        "#TODO: Fix display issues\n",
        "def show_img(num):\n",
        "  w=10\n",
        "  h=10\n",
        "  fig=plt.figure(figsize=(num, 1))\n",
        "  columns = 28\n",
        "  rows = 28\n",
        "  for image, label in train_dataloader:\n",
        "    for i in range(1, columns*rows +1):\n",
        "      fig.add_subplot(rows, columns, i)\n",
        "      plt.imshow(image.view(-1, 28))\n",
        "    break\n",
        "  plt.show()\n",
        "show_img(4)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQsAAABZCAYAAAApZAEaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nEEIUoWAhhChCwUIIUcT/AZ9hPKsw1RUTAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 288x72 with 784 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6a4GU0xhl9zA",
        "colab_type": "code",
        "outputId": "5b6a95ab-7db4-414d-8c52-ef2b4327ae22",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YJhOB6IsXvmk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#set up a Sequential model input 28*28, ouput 10 catagories\n",
        "import torch.nn.functional as F\n",
        "import torch.nn as nn\n",
        "\n",
        "model = nn.Sequential(nn.Linear(28*28, 128), \n",
        "                      nn.ReLU(), \n",
        "                      nn.Linear(128, 64), \n",
        "                      nn.ReLU(), \n",
        "                      nn.Linear(64, 10), \n",
        "                      nn.LogSoftmax(dim=1)).to(device)\n",
        "\n",
        "#loss criterion\n",
        "criterion = nn.NLLLoss()\n",
        "#optimizer\n",
        "lr=.01\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LbQg6aaroYFl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NkGZCV9oYpha",
        "colab_type": "code",
        "outputId": "cd5dacee-811a-4f14-9d06-6ece6d60a7f7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "#set up train test code\n",
        "epochs = 10\n",
        "\n",
        "for i in range(epochs):\n",
        "  running_loss = 0\n",
        "  for image, label in train_dataloader:\n",
        "    \n",
        "    #zero grads for each pass through model\n",
        "    optimizer.zero_grad()\n",
        "    \n",
        "    #resize images and send images and labels to GPU\n",
        "    image = image.view(image.shape[0], -1)\n",
        "    image, label = image.to(device), label.to(device)\n",
        "    \n",
        "    #pass each batch through the model\n",
        "    output = model(image)\n",
        "    \n",
        "    #calculate loss, back propogate, gradient descent\n",
        "    loss = criterion(output, label)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    \n",
        "    #add up loss then print after each epoch\n",
        "    running_loss += loss.item()\n",
        "  print('Epoch: ', i, 'Loss: ', running_loss/len(train_dataloader))\n",
        "  \n",
        "  #set model to eval with no_grad tracking\n",
        "  accuracy = 0\n",
        "  with torch.no_grad():\n",
        "    model.eval()\n",
        "    for images, labels in test_dataloader:\n",
        "      images = images.view(images.shape[0], -1)\n",
        "      \n",
        "      images, labels = images.to(device), labels.to(device)\n",
        "      \n",
        "      #model output is log_softmax must do exp to get actual value\n",
        "      ps = torch.exp(model(images))\n",
        "      \n",
        "      #get top class\n",
        "      topk, top_class = ps.topk(1, dim=1)\n",
        "      \n",
        "      #print accuracy\n",
        "      results = top_class == labels.view(top_class.shape[0], 1)\n",
        "      accuracy += torch.mean(results.type(torch.FloatTensor))\n",
        "  print('Accuracy: ', (accuracy.item()/len(test_dataloader))*100, '%')\n",
        "  model.train()\n",
        "  \n",
        "    "
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch:  0 Loss:  0.16430920539038876\n",
            "Accuracy:  96.02000000000001 %\n",
            "Epoch:  1 Loss:  0.1471957941090067\n",
            "Accuracy:  95.54 %\n",
            "Epoch:  2 Loss:  0.1519453218307967\n",
            "Accuracy:  95.41 %\n",
            "Epoch:  3 Loss:  0.154054517046238\n",
            "Accuracy:  95.24000000000001 %\n",
            "Epoch:  4 Loss:  0.14453279988610496\n",
            "Accuracy:  95.74000000000001 %\n",
            "Epoch:  5 Loss:  0.15225821963272368\n",
            "Accuracy:  95.19999999999999 %\n",
            "Epoch:  6 Loss:  0.15330865694146292\n",
            "Accuracy:  95.77 %\n",
            "Epoch:  7 Loss:  0.15115810940964147\n",
            "Accuracy:  95.87 %\n",
            "Epoch:  8 Loss:  0.14904419819082057\n",
            "Accuracy:  95.83 %\n",
            "Epoch:  9 Loss:  0.1589305373805808\n",
            "Accuracy:  95.47 %\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}